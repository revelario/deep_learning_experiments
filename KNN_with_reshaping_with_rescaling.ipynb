{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display, Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from six.moves import range\n",
    "import time\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function to read in the batch files\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin') # encoding latin otherwise no worky\n",
    "    fo.close()\n",
    "    return(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_center_pixels(data):\n",
    "    scale = StandardScaler().fit(data)\n",
    "    old_mean = scale.mean_.astype('float32')\n",
    "    old_sigma = np.sqrt(scale.var_).astype('float32')\n",
    "    return((data - old_mean) * 0.5 / old_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read in the data\n",
    "## manually is easy\n",
    "data_batch_1 = unpickle('cifar-10-batches-py/data_batch_1')\n",
    "data_batch_2 = unpickle('cifar-10-batches-py/data_batch_2')\n",
    "data_batch_3 = unpickle('cifar-10-batches-py/data_batch_3')\n",
    "data_batch_4 = unpickle('cifar-10-batches-py/data_batch_4')\n",
    "data_batch_5 = unpickle('cifar-10-batches-py/data_batch_5')\n",
    "test_batch = unpickle('cifar-10-batches-py/test_batch')\n",
    "label_map = unpickle('cifar-10-batches-py/batches.meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n"
     ]
    }
   ],
   "source": [
    "## stack up the data batches\n",
    "all_data = []\n",
    "\n",
    "for i in data_batch_1['data']:\n",
    "    all_data.append(i)\n",
    "    \n",
    "for i in data_batch_2['data']:\n",
    "    all_data.append(i)\n",
    "\n",
    "for i in data_batch_3['data']:\n",
    "    all_data.append(i)\n",
    "\n",
    "for i in data_batch_4['data']:\n",
    "    all_data.append(i)\n",
    "    \n",
    "for i in data_batch_5['data']:\n",
    "    all_data.append(i)\n",
    "\n",
    "all_data = np.array(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "## stack up the label data\n",
    "all_labels = data_batch_1['labels'] + data_batch_2['labels'] + data_batch_3['labels'] + data_batch_4['labels'] + data_batch_5['labels']\n",
    "all_labels = np.array(all_labels)\n",
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data_rgb = all_data.reshape(50000, 3, 32, 32).transpose(0,2,3,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_rgb_flattened = np.array([i.flatten() for i in all_data_rgb])\n",
    "all_data_rgb_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_rgb = test_batch['data'].reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype('float32')\n",
    "test_data_rgb_flattened = np.array([i.flatten() for i in test_data_rgb])\n",
    "test_data_rgb_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Wall time:  24.93022108078003\n",
      "Predict Wall time:  3380.7372150421143\n",
      "KNN Accuracy Score:  0.3383\n"
     ]
    }
   ],
   "source": [
    "## trying KNN with reshaped pixels, with scaling\n",
    "\n",
    "t0 = time.time()\n",
    "knn = KNeighborsClassifier()\n",
    "knn_fit = knn.fit(zero_center_pixels(all_data_rgb_flattened), all_labels)\n",
    "print('Train Wall time: ', time.time() - t0)\n",
    "\n",
    "t1 = time.time()\n",
    "knn_preds = knn_fit.predict(zero_center_pixels(test_data_rgb_flattened))\n",
    "print('Predict Wall time: ', time.time() - t1)\n",
    "\n",
    "print('KNN Accuracy Score: ', accuracy_score(test_batch['labels'], knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## figure out which approach to use for rotated testing\n",
    "## pick the best performing one from above\n",
    "\n",
    "rotated_dataset = []\n",
    "for i in :\n",
    "    rotated_i = np.rot90(i)\n",
    "    rotated_dataset.append(rotated_i)\n",
    "rotated_dataset = np.array(rotated_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## trying KNN with rotated image dataset\n",
    "\n",
    "t0 = time.time()\n",
    "knn = KNeighborsClassifier()\n",
    "knn_fit = knn.fit(zero_center_pixels(all_data_rgb_flattened), train_labels)\n",
    "print('Train Wall time: ', time.time() - t0)\n",
    "\n",
    "t1 = time.time()\n",
    "knn_preds = knn_fit.predict(zero_center_pixels(test_data_rgb_flattened))\n",
    "print('Predict Wall time: ', time.time() - t1)\n",
    "\n",
    "print('KNN Accuracy Score: ', accuracy_score(test_batch['labels'], knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
